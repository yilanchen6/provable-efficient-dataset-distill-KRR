
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<style type="text/css">
body {
    font-family: "Arial", "calibri", "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica,  "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}

h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

img {
  max-width: 100%;
  height: auto;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
}
.maintext {
    font-size: 17px;
}

video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.example-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #4cd468;
  color: white !important;
  font-size: 20px;
  width: 220px;
  font-weight: 600;
}
.example-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.example-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}



/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title>Provable and Efficient Dataset Distillation for Kernel Ridge Regression</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="The Importance of Prompt Tuning for Automated Neuron Explanations"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    </head>

 <body>


<div class="container">
    <div class="paper-title">
    <h1> 
        Provable and Efficient Dataset Distillation <br>
        for Kernel Ridge Regression
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://yilanchen6.github.io/">Yilan Chen<sup>1</sup></a>,
                <a href="https://weihuang05.github.io/">Wei Huang<sup>2</sup></a>,
                <a href="https://lilywenglab.github.io/">Tsui-Wei (Lily) Weng<sup>1</sup></a>
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span> <sup>1</sup>UCSD</span>
            <span> <sup>2</sup>RIEKN AIP</span>
        </div>


        <div class="affil-row">
            <div class="venue text-center"><b>ICLR 2024</b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://openreview.net/pdf?id=WI2VpcBdnd">
                <span class="material-icons"> description </span> 
                <div class="maintext">Paper</div> 
            </a>
            <div class="paper-btn-coming-soon">
                <a class="paper-btn" href="https://github.com/Trustworthy-ML-Lab/provable-efficient-dataset-distill-KRR">
                    <span class="material-icons"> code </span>
                    <div class="maintext"> Code </div>
                </a>
            </div>
        </div></div>
    </div>
    

    
    <section id="abstract">
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p class="maintext">
                Deep learning models are now trained on increasingly larger datasets, making it
                crucial to reduce computational costs and improve data quality. Dataset distillation
                aims to distill a large dataset into a small synthesized dataset such that models
                trained on it can achieve similar performance to those trained on the original
                dataset. While there have been many empirical efforts to improve dataset distillation
                algorithms, a thorough theoretical analysis and provable, efficient algorithms are
                still lacking. </p>
            <p class="maintext">
                In this paper, by focusing on dataset distillation for kernel ridge
                regression (KRR), we show that one data point per class is already necessary and
                sufficient to recover the original model’s performance in many settings. For linear
                ridge regression and KRR with surjective feature mappings, we provide necessary
                and sufficient conditions for the distilled dataset to recover the original model’s
                parameters. For KRR with injective feature mappings of deep neural networks, we
                show that while one data point per class is not sufficient in general, k+1 data points
                can be sufficient for deep linear neural networks, where k is the number of classes.
                Our theoretical results enable directly constructing analytical solutions for distilled
                datasets, resulting in a provable and efficient dataset distillation algorithm for KRR.
                We verify our theory experimentally and show that our algorithm outperforms
                previous work such as KIP while being significantly more efficient, e.g. 15840×
                faster on CIFAR-100.</p>
        </div>
    </section>
    <section id="Overview">
        <div class="mx-auto">
            <center><img class="card-img-top" src="assets/overview.gif" style="max-width: none;"></center>
            <center>
                <p class="caption">
                    Overview of our paper.
                </p>
            </center>
        </div>
    </section>
    <section id="What is Conformal Prediction (CP)">
        <hr>
        <h2>What is Conformal Prediction (CP)</h2>
            
            <div class="mx-auto">
                <center><img class="card-img-top" src="assets/CP_example.PNG"></center>
                <center><p class="caption">An example of conformal prediction from <a href="#Ref1">[1]</a></p></center>
            </div>
            <br>
            <div class="flex-row">
                <div class="mx-auto">
                    <p class="maintext">
                        Conformal prediction has been a powerful tool to quantify
                    prediction uncertainties of modern machine learning models. For
                    classification tasks, given a test input \(x_{n+1}\), it could generate
                    a prediction set \(C(x_{n+1})\) with coverage guarantee:
                    $$
                    \mathbb P [y_{n+1} \in C(x_{n+1})] \geq 1-\alpha.
                    $$
                    </p>
                    <p class="maintext">
                        In conformal prediction, usually a (non)-conformity score function  \(S(x, y)\) is defined, which measures
                        how label \(y\) conforms to input \(x\). The prediction set is constructed as:
                        $$
                            C(x) = \{y \mid S(x, y) \leq \tau \},
                        $$
                        where \(\tau\) is a threshold computed on a seperate calibration set, according to the target coverage
                        level \(1-\alpha\).
                    </p>
                </div>
            </div>
    </section>
    <section  id="Adversarial robustness of conformal prediction">
        <hr>
        <h2>Adversarial robustness of conformal prediction</h2>
        <p class="maintext">
        Under adversarial attack, the coverage guarantee no longer hold.
        To rebuild the coverage guarantee, RSCP<a href="#Ref2">[2]</a> is proposed to provide adversarially robust conformal prediction.
        RSCP proposed to apply conformal prediction on (non)-conformity scores:
        $$
        \tilde S(x, y) = \Phi^{-1}[S_{\text{RS}}(x, y)] = \Phi^{-1}[\mathbb E_{\delta \sim \mathcal N(0, \sigma^2I)}S(x + \delta, y)],
        $$
        where \(\Phi\) denotes Gaussian cdf. The randomized smoothed score \(\tilde S(x, y)\) is Lipschitz continuous with constant
        \(1/\sigma\), hence the score of adversarially perturbed example could be bound:
        $$
        \tilde S(\tilde x, y) \leq \tilde S(x, y) + \frac{\epsilon}{\sigma},
        $$
        where \(\tilde x\) is the perturbed example that \(\|\tilde x - x\|_2 \leq \epsilon\).
        </p>
        <p class="maintext">
        However, RSCP still faces two challenges:<br><br>
        <b>Challenge 1: The robustness guarantee of RSCP is flawed.</b> RSCP
        introduces randomized smoothing to provide robustness guarantee. Unfortunately, the derived
        guarantee is invalid when Monte Carlo sampling is used for randomized smoothing, which is how
        randomized smoothing is implemented in practice <a href="#Ref3">[3]</a>. Therefore, their robustness
        certification is invalid, despite empirically working well.
        <br> <br>
        <b>Challenge 2: RSCP has low efficiency.</b> The average
        size of prediction sets of RSCP is much larger than the vanilla conformal prediction.
        </p>
    </section>
    <section>
        <hr>
        <h2>Address challenge 1: RSCP+ framework</h2>
        <p class="maintext">
            To address the technique flaw in RSCP, we proposed RSCP+, a novel framework to provide guaranteed 
            robustness for conformal prediction. The key idea is utilizing the Monte-Carlo estimator directly as the 
            conformity score in conformal prediction, and bound the score of perturbed examples. To be more specific, the bound contains three parts:
            <ol class="maintext">
                <li>Bound between \(S_{\text{RS}}\) of perturbed input and original input. This bound is guaranteed by randomized smoothing.</li>
                <li>Error from Monte Carlo approximation of perturbed input score, bounded by Hoeffding's inequality. </li>
                <li>Error from Monte Carlo approximation of clean input score, bounded by Hoeffding's inequality. </li>
            </ol>
        </p>
        <p class="maintext">
            With this bound, we could provide guaranteed robustness with our RSCP+. <br>
            <b>RSCP+ algorithm</b><br>
            <b>Input:</b> Input image \(x_{n+1}\), calibration set \(D_{cal}\), target coverage level \(1 - \alpha, \epsilon, \sigma, \beta\). <br>
            <b>Output:</b> Guaranteed robust prediction set \(C_\epsilon^+\).<br>
            <ol class="maintext">
                <li>Calculate calibration scores with randomized smoothing \(\{\hat{S}_{\text{RS}}(x, y)\}_{(x, y) \in D_{\text{cal}}}\).\(\hat{S}_{\text{RS}}(x, y) =\frac{1}{N_{\text{MC}}} 
                    \sum_{i=1}^{N_{\text{MC}}} S(x + \delta_i, y), \delta_i \sim \mathcal{N}(0, \sigma^2 I_p)\) is the Monte Carlo approximation of \(S_{\text{RS}}\).</li>  
                <li>Calculate threshold \(\tau_{\text{MC}}\) as \(\frac{1 - \alpha - 2\beta}{1 + 1 / |D_{\text{cal}}|}\) empirical quantile of  calibration scores.</li>
                <li>Calculate test conformity score for each class with randomized smoothing \({\hat{S}_{\text{RS}}(\tilde{x}_{n+1}, k)}_{k=1}^K\).</li>
                <li>Calculate prediction set \(C_\epsilon^+\) with Eq. (17) in the paper.</li>
            </ol>
        </p>
        <!-- <div class="mx-auto">
            <center><img class="card-img-top" src="assets/proof_diagram_v8.png"></center>
            <center>
                <p class="caption">
                    Diagram showing the main idea of RSCP+.
                </p>
            </center>
        </div> -->
    </section>
    <section>
        <hr>
        <h2>Address challenge 2: Post-Training Transformation (PTT) and Robust Conformal Training (RCT)</h2>
        <p class="maintext">
            To improve the efficiency of RSCP, we proposed two methods, 
            Post-Training Transformation (PTT) and Robust Conformal Training (RCT).
        </p>
        <div style="margin-left: 30px;">
            <h3 style="font-size:x-large;">Method 1: Post-Training Transformation (PTT)</h3>
            <p class="maintext">
            PTT consists of two transformations on the base conformity score: (1) ranking transformation and (2) sigmoid transformation.
            <br>
            <b>Ranking transformation. </b> The ranking transformation utilizes a hold out set:
            $$
                \mathcal{Q}_{\text{rank}}(s) = \frac{r\left[s; \{S(x, y)\}_{(x, y) \in D_{holdout}}\right]}{|D_{\text{holdout}}|}.
            $$
            </p>
            <p class="maintext"><b>Sigmoid transformation. </b> In this step, a sigmoid function \(\phi\) is applied on \(S\):
                $$
                \mathcal{Q}_{\text{sig}}(s) = \phi\left[(s - b) / T\right],
                $$
                where \(b, T\) are hyper-parameters controlling this transformation.
            </p>
            <h3 style="font-size:x-large;">Method 2: Robust Conformal Training (RCT)</h3>
            <p class="maintext">
                Besides PTT which is a post-training method, we propose a novel training pipeline called Robust Conformal Training (RCT).
                The key idea is to simulate the conformal prediction procedure during trainig.
                The training pipeline is shown in the figure below. The training objective is defined as:
                $$
                L(x, y_{\text{gt}}) = L_{\text{class}}(c(x, y; \tau^{\text{soft}}), y_{\text{gt}}) + \lambda L_{\text{size}}(c(x, y; \tau^{\text{soft}})),
                $$
                where the classification loss
                $$
                L_{\text{class}}(c(x, y; \tau^{\text{soft}}), y_{\text{gt}}) = 1 - c(x, y_{\text{gt}}; \tau^{\text{soft}}),
                $$
                and the size loss
                $$
                L_{\text{size}}(c(x, y; \tau^{\text{soft}}))  = \max(0, \sum_{y=1}^K c(x, y;\tau^{\text{soft}}) - \kappa).
                $$
            </p>
            <div class="mx-auto">
                <center><img class="card-img-top" src="assets/RCT_pipeline_v12.PNG"></center>
                <center><p class="caption">Training pipeline of RCT.</p></center>
            </div>
        </div>
    </section>
    <section>
        <hr>
        <h2>Results</h2>
        <p class="maintext">
            The tables below show the average size of prediction sets over three vision datasets. 
            The baseline method gives trivial prediction sets (predict full label set) when trying to provide guaranteed robustness.
            With our methods, we provide the first meaningful, provably robust conformal prediction,
            with boosted efficiency by up to <b>4.36×, 5.46×, and 16.9×</b> on CIFAR10, CIFAR100 and ImageNet, respectively.
        </p>
        <div class="mx-auto">
            <center><img class="card-img-top" style="max-width: 90%;height: auto;" src="assets/result1.png"></center>
            <center><p class="caption">Average size of prediction sets on CIFAR10 & CIFAR100</p></center>
        </div>
        <div class="mx-auto">
            <center><img class="card-img-top" style="max-width: 70%;height: auto;" src="assets/result2.png"></center>
            <center><p class="caption">Average size of prediction sets on ImageNet</p></center>
        </div>
    </section>
    <section>
        <hr>
        <h2>Related works</h2>
        <p class="maintext">
        [1] Angelopoulos, Anastasios Nikolas, Stephen Bates, Michael Jordan, and Jitendra Malik.
        <a id="Ref1" href="https://arxiv.org/abs/2009.14193">"Uncertainty Sets for Image Classifiers using Conformal Prediction."</a>
        In International Conference on Learning Representations. 2020.
        <br>
        [2] Gendler, Asaf, Tsui-Wei Weng, Luca Daniel, and Yaniv Romano.
        <a id="Ref2" href="https://openreview.net/forum?id=9L1BsI4wP1H">"Adversarially robust conformal prediction."</a>
        In International Conference on Learning Representations. 2021.
        <br>
        [3] Cohen, Jeremy, Elan Rosenfeld, and Zico Kolter.
        <a id="Ref3" href="https://proceedings.mlr.press/v97/cohen19c.html">"Certified adversarial robustness via randomized smoothing."</a>
        In international conference on machine learning, pp. 1310-1320. PMLR, 2019.</p>
    </section>
    <section class="maintext">
        <hr>
        <h2>Cite this work</h2>
        G. Yan, Y. Romano and T.-W. Weng, <a href="https://openreview.net/pdf?id=BWAhEjXjeG">
            <b>Provably Robust Conformal Prediction with Improved Efficiency</b>
        </a>, ICLR 2024.
        <pre>
            <code>
@inproceedings{
    yan2024provably,
    title={Provably Robust Conformal Prediction with Improved Efficiency},
    author={Ge Yan and Yaniv Romano and Tsui-Wei Weng},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=BWAhEjXjeG}
    }
            </code>
        </pre>
    </section>
    <section>
        <hr>
        This webpage template was recycled from <a href='https://nv-tlabs.github.io/LION/'>here</a>.
        <center><p><a href='https://accessibility.ucsd.edu/'><b>Accessibility</b></a></p></center>
    </section>
</div>
</body>
</html>
